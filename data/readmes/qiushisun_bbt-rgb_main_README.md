# Make Prompt-based Black-Box Tuning Colorful: Boosting Model Generalization from Three Orthogonal Perspectives

[![arXiv](https://img.shields.io/badge/arXiv-2305.08088-b31b1b.svg)](https://arxiv.org/abs/2305.08088) 
![License](https://img.shields.io/badge/License-MIT-blue)

## Updates

- 2024/01/20: BBT-RGB is accepted by LREC-COLING 2024. ðŸŽ‰
- 2023/05/03: Release the first version of BBT-RGB, please check our [paper](https://arxiv.org/abs/2305.08088). ðŸŒˆ



## Introduction

We describe BBT-RGB in this paper, a suite of straightforward and complementary techniques for enhancing the efficiency and performance of black-box optimization. Specifically, our method includes three plug-and-play components: (1) Two-stage derivative-free optimization strategy that facilitates fast convergence and mitigates overfitting; (2) Automatic verbalizer construction with its novel usage under few-shot settings; (3) Better prompt initialization policy based on instruction search and auto-selected demonstration.



<img src="./images/BBT-RGB-Overview.png" alt="BBT-RGB-Overview" style="zoom:20%;" />



## Preparing the Environment

```bash
conda create --name bbtrgb python=3.8
conda activate bbtrgb
pip install transformers==4.1.1
pip install datasets
pip install fastNLP
pip install cma
pip install sklearn
```


## Performance

Them main results on RoBERTa-Large are shown below. The best results are in bold. Some baselines are collected from [Black-Box-Tuning](https://github.com/txsun1997/Black-Box-Tuning).

| Method            | Tunable Params | SST-2 acc  | Yelp P. acc | AG's News acc | DBPedia acc | MRPC F1 | SNLI acc | RTE acc | Avg.   |
|-------------------|----------------|------------|-------------|---------------|-------------|---------|----------|---------|--------|
| Model Tuning      | 355M           | 85.39Â±2.84  | 91.82Â±0.79   | 86.36Â±1.85     | 97.98Â±0.14   | 77.35Â±5.70 | 54.64Â±5.29 | 58.60Â±6.21 | **78.88** |
| Prompt Tuning     | 50K            | 68.23Â±3.78  | 61.02Â±6.65   | 84.81Â±0.66     | 87.75Â±1.48   | 51.61Â±8.67 | 36.13Â±1.51 | 54.69Â±3.79 | 63.46  |
| P-Tuning v2       | 1.2M           | 64.33Â±3.05  | **92.63Â±1.39** | 83.46Â±1.01     | 97.05Â±0.41   | 68.14Â±3.89 | 36.89Â±0.79 | 50.78Â±2.28 | 70.47  |
| Adapter           | 2.4M           | 83.91Â±2.90  | 90.99Â±2.86   | 86.01Â±2.18     | **97.99Â±0.07** | 69.20Â±3.58 | 57.46Â±6.63 | 48.62Â±4.74 | 76.31  |
| LoRA              | 786K           | **88.49Â±2.90** | 90.21Â±4.00   | **87.09Â±0.85** | 97.86Â±0.17   | 72.14Â±2.23 | **61.03Â±8.55** | 49.22Â±5.12 | **78.01** |
| BitFit            | 172K           | 81.19Â±6.08  | 88.63Â±6.69   | 86.83Â±0.62     | 94.42Â±0.94   | 66.26Â±6.81 | 53.42Â±10.63| 52.59Â±5.31 | 74.76  |
| Manual Prompt     | 0              | 79.82       | 89.65        | 76.96          | 41.33        | 67.40    | 31.11     | 51.62    | 62.56  |
| In-Context Learning | 0            | 79.79Â±3.06  | 85.38Â±3.92   | 62.21Â±13.46    | 34.83Â±7.59   | 45.81Â±6.67 | 47.11Â±0.63 | 60.36Â±1.56 | 59.36  |
| BBT               | 500            | 89.56Â±0.25  | 91.50Â±0.16   | 81.51Â±0.79     | 79.99Â±2.95   | 61.56Â±4.34 | 46.58Â±1.33 | 52.59Â±2.21 | 71.90  |
| BBTv2             | 12K            | 90.33Â±1.73  | 92.86Â±0.62   | 85.28Â±0.49     | 93.64Â±0.68   | 77.01Â±4.73 | 57.27Â±2.27 | 56.68Â±3.32 | 79.01  |
| **BBT-RGB**| 12K            | **92.89Â±0.26** | **94.20Â±0.48** | **85.60Â±0.41** | **94.41Â±0.73** | **79.49Â±1.84** | **60.71Â±0.66** | **61.82Â±1.20** | **81.30** |



## Acknowledgement

This is also derived from a prize-winning solution of the [First International Algorithm Case Competition: PLM Tuning Track, Guangdong-Hong Kong-Macao Greater Bay Area](https://iacc.pazhoulab-huangpu.com/). Part of the codes are adapted from [Black-Box-Tuning](https://github.com/txsun1997/Black-Box-Tuning).

## Citation

Please consider citing us if you find this repository useful.ðŸ‘‡

```bibtex
@misc{sun2023bbtrgb,
      title         = {Make Prompt-based Black-Box Tuning Colorful: Boosting Model Generalization from Three Orthogonal Perspectives}, 
      author        = {Qiushi Sun and Chengcheng Han and Nuo Chen and Renyu Zhu and Jingyang Gong and Xiang Li and Ming Gao},
      year          = {2023},
      eprint        = {2305.08088},
      archivePrefix = {arXiv},
      primaryClass  = {cs.CL}
}
```

